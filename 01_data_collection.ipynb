{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "96fa52e0-262a-4d18-bacd-2b8a7e32d0e4",
   "metadata": {},
   "source": [
    "### Analyzing, Cleaning and Manipulating Datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e34e94de-45d7-49d2-8315-6a71f4ba0130",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fc14a4a-7764-4379-a94c-890c52b5234c",
   "metadata": {},
   "source": [
    "### Data Visualization Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592ee618-4440-4304-9ca5-2190d7769baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c6d28d-3462-4c47-8b86-eb99cd6d9c01",
   "metadata": {},
   "source": [
    "### Maschine learning Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f742037f-d836-471f-898b-90d4fd256e35",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c098436-93cf-425d-b2e6-3be0f8246de8",
   "metadata": {},
   "source": [
    "### Read the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4d7063-ee1f-457d-9e84-00eede6eccb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"/Users/sophiekersten/Desktop/thesis/tracks_features.csv\")\n",
    "\n",
    "\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad4f83c4-791a-4e6a-895c-70086c2f183a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dataset.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b27823-917b-4ae5-a814-ca37909b9c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['artists'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0aeb8c-389a-4f04-91bb-b3ce50cff500",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[\n",
    "    (dataset['duration_ms'] > 60000) &  # longer than one minute\n",
    "    (dataset['instrumentalness'] < 0.9) # not only instrumental songs\n",
    "]\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa1210f-6723-4db3-99a3-88b07f66bb4c",
   "metadata": {},
   "source": [
    "### Get Country Data from Musicbrainz - part 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307f01f1-622b-430e-a4f9-a27f4ca703ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "all_artists = dataset['artists'].unique()\n",
    "\n",
    "\n",
    "artists_part1 = all_artists[:len(all_artists)//2]\n",
    "CACHE_FILE = \"artist_data_part1.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41c0911b-0e74-4620-8637-2e6efc3ed035",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_artist_info(artist_name):\n",
    "    base_url = \"https://musicbrainz.org/ws/2/artist/\"\n",
    "    params = {\n",
    "        \"query\": f\"artist:{artist_name}\",\n",
    "        \"fmt\": \"json\"\n",
    "    }\n",
    "    headers = {\n",
    "        \"User-Agent\": \"TrackExplorer/1.0 (sophiekersten@gmx.com)\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(base_url, params=params, headers=headers, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if data[\"artists\"]:\n",
    "                artist_info = data[\"artists\"][0]\n",
    "                return {\n",
    "                    \"country\": artist_info.get(\"country\", \"Unknown\"),\n",
    "                    \"type\": artist_info.get(\"type\", \"Unknown\"),\n",
    "                    \"gender\": artist_info.get(\"gender\", \"Unknown\")\n",
    "                }\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"â° Timeout bei {artist_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei {artist_name}: {e}\")\n",
    "\n",
    "    return {\n",
    "        \"country\": \"Unknown\",\n",
    "        \"type\": \"Unknown\",\n",
    "        \"gender\": \"Unknown\"\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b557de-ee34-4533-98bd-6c44ab583ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for artist in tqdm(artists_part1):\n",
    "    if artist not in artist_data:\n",
    "        info = get_artist_info(artist)\n",
    "        artist_data[artist] = info\n",
    "        time.sleep(1)  \n",
    "\n",
    "        if len(artist_data) % 500 == 0:\n",
    "            with open(CACHE_FILE, \"w\") as f:\n",
    "                json.dump(artist_data, f)\n",
    "\n",
    "\n",
    "with open(CACHE_FILE, \"w\") as f:\n",
    "    json.dump(artist_data, f)\n",
    "\n",
    "print(\"part1 done and safed: 'artist_data_part1.json'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b09d862-fa78-4c4a-8851-1f3a6e51ba56",
   "metadata": {},
   "source": [
    "### Get Country Data from Musicbrainz - part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcd4f20-5a43-406d-907c-e91c69b923be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "all_artists = dataset['artists'].unique()\n",
    "\n",
    "\n",
    "artists_part2 = all_artists[len(all_artists)//2:]\n",
    "CACHE_FILE = \"artist_data_part2.json\"\n",
    "\n",
    "\n",
    "def get_artist_info(artist_name):\n",
    "    base_url = \"https://musicbrainz.org/ws/2/artist/\"\n",
    "    params = {\n",
    "        \"query\": f\"artist:{artist_name}\",\n",
    "        \"fmt\": \"json\"\n",
    "    }\n",
    "    headers = {\n",
    "        \"User-Agent\": \"TrackExplorer/1.0 (sophiekersten@gmx.com)\"\n",
    "    }\n",
    "\n",
    "    try:\n",
    "        response = requests.get(base_url, params=params, headers=headers, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            if data[\"artists\"]:\n",
    "                artist_info = data[\"artists\"][0]\n",
    "                return {\n",
    "                    \"country\": artist_info.get(\"country\", \"Unknown\"),\n",
    "                    \"type\": artist_info.get(\"type\", \"Unknown\"),\n",
    "                    \"gender\": artist_info.get(\"gender\", \"Unknown\")\n",
    "                }\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"Timeout bei {artist_name}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei {artist_name}: {e}\")\n",
    "\n",
    "    return {\n",
    "        \"country\": \"Unknown\",\n",
    "        \"type\": \"Unknown\",\n",
    "        \"gender\": \"Unknown\"\n",
    "    }\n",
    "\n",
    "\n",
    "if os.path.exists(CACHE_FILE):\n",
    "    with open(CACHE_FILE, \"r\") as f:\n",
    "        artist_data = json.load(f)\n",
    "else:\n",
    "    artist_data = {}\n",
    "\n",
    "\n",
    "for artist in tqdm(artists_part2):\n",
    "    if artist not in artist_data:\n",
    "        info = get_artist_info(artist)\n",
    "        artist_data[artist] = info\n",
    "        time.sleep(1)\n",
    "\n",
    "        if len(artist_data) % 500 == 0:\n",
    "            with open(CACHE_FILE, \"w\") as f:\n",
    "                json.dump(artist_data, f)\n",
    "\n",
    "\n",
    "with open(CACHE_FILE, \"w\") as f:\n",
    "    json.dump(artist_data, f)\n",
    "\n",
    "print(\"part2 done and safed:  'artist_data_part2.json'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceec82f6-16c7-4597-826e-89d253bf3d47",
   "metadata": {},
   "source": [
    "## Combining part 1 & 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1c8d95-6181-45e4-81ce-7e872807c4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import ast\n",
    "\n",
    "\n",
    "with open(\"artist_data_part1.json\", \"r\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "rows = []\n",
    "\n",
    "for key, value in data.items():\n",
    "    \n",
    "    artist_list = ast.literal_eval(key)\n",
    "    artist_name = artist_list[0] if artist_list else \"Unknown\"\n",
    "\n",
    "    row = {\n",
    "        \"artist\": artist_name,\n",
    "        \"country\": value.get(\"country\", \"Unknown\"),\n",
    "        \"type\": value.get(\"type\", \"Unknown\"),\n",
    "        \"gender\": value.get(\"gender\", \"Unknown\")\n",
    "    }\n",
    "    rows.append(row)\n",
    "\n",
    "\n",
    "df_part1 = pd.DataFrame(rows)\n",
    "df_part1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5a3638-822c-4043-91f9-74335cde35cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('artist_data_part2.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4bab153-f8fe-47f8-a601-4a5b64202972",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import ast \n",
    "\n",
    "tidy_rows = []\n",
    "\n",
    "for k, v in data.items():\n",
    "    try:\n",
    "        artists = ast.literal_eval(k) \n",
    "        for artist in artists:\n",
    "            tidy_rows.append({\n",
    "                \"artist\": artist,\n",
    "                \"gender\": v.get(\"gender\", \"Unknown\"),\n",
    "                \"country\": v.get(\"country\", \"Unknown\"),\n",
    "                \"type\": v.get(\"type\", \"Unknown\")\n",
    "            })\n",
    "    except:\n",
    "        print(f\"mistake {k}\")\n",
    "\n",
    "df_part2 = pd.DataFrame(tidy_rows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd57bc1-5818-4954-9e7a-b340d7abfa7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.concat([df_part1, df_part2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e06960e-728a-43c4-933a-8e2065e61b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4bb55a6-a4b7-492b-86e5-98d54f5166a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "dataset[\"artists\"] = dataset[\"artists\"].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "\n",
    "dataset[\"artist\"] = dataset[\"artists\"].apply(lambda x: x[0] if isinstance(x, list) else x)\n",
    "\n",
    "\n",
    "df_merged = dataset.merge(df_all, on=\"artist\", how=\"left\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf138451-d4e0-4943-b3fa-493bb5b20324",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3997efbc-1f75-469b-b1db-f379f3b648c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df_merged[(df_merged[\"gender\"] != \"Unknown\") & (df_merged[\"country\"] != \"Unknown\")]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da271fc-7234-470e-82a3-2070e8857353",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = filtered_df.drop_duplicates(subset=[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940f3ba1-7efa-4d07-bcbd-93783a9b8359",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(df_cleaned)\n",
    "\n",
    "country_counts = df_cleaned['country'].value_counts()\n",
    "countries_over_500 = country_counts[country_counts > 500]\n",
    "print(countries_over_500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54eed7a9-b01f-4fec-a46f-47a29331fd2e",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3e1270-33e2-46b5-94b5-dc50c72c5fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = pd.read_csv(\"/Users/sophiekersten/Desktop/thesis/spotify_metadata.csv\")\n",
    "\n",
    "\n",
    "metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fdb279a-bff7-45fb-98aa-b0e13155d701",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artist_data = pd.DataFrame(artist_results)\n",
    "print(\"rows\", df_artist_data.columns.tolist())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17223d75-357e-4aeb-a142-f0ab78943d9e",
   "metadata": {},
   "source": [
    "## get popularity Score and Genre from Spotify API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04437888-a016-42d3-8cfd-deda89808985",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "# Spotify API Setup\n",
    "client_id = \"94dfa922c1594dceab2e83b4566f36ec\"\n",
    "client_secret = \"d3f1d099d4294020a02e6a191a08c9a2\"\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id=client_id, client_secret=client_secret))\n",
    "\n",
    "df_cleaned['artist_ids'] = df_cleaned['artist_ids'].apply(lambda x: ast.literal_eval(x) if isinstance(x, str) else x)\n",
    "\n",
    "df_valid = df_cleaned[df_cleaned['artist_ids'].apply(lambda x: isinstance(x, list) and len(x) > 0)].copy()\n",
    "df_valid['main_artist_id'] = df_valid['artist_ids'].apply(lambda x: x[0])\n",
    "\n",
    "chunks = np.array_split(df_valid, 4)\n",
    "part_index = 3 \n",
    "df_part = chunks[part_index].copy()\n",
    "\n",
    "artist_cache_file = f\"artist_data_cache_part{part_index+1}.json\"\n",
    "if os.path.exists(artist_cache_file):\n",
    "    with open(artist_cache_file, \"r\") as f:\n",
    "        artist_cache = json.load(f)\n",
    "else:\n",
    "    artist_cache = {}\n",
    "\n",
    "unique_artist_ids = df_part['main_artist_id'].dropna().unique().tolist()\n",
    "artist_ids_to_query = [aid for aid in unique_artist_ids if aid not in artist_cache]\n",
    "\n",
    "\n",
    "artist_results = []\n",
    "for idx, artist_id in enumerate(tqdm(artist_ids_to_query, desc=f\"Part {part_index+1}\")):\n",
    "    artist_data = {\n",
    "        \"artist_id\": artist_id,\n",
    "        \"artist_popularity\": None,\n",
    "        \"artist_genres\": []\n",
    "    }\n",
    "\n",
    "    for attempt in range(5):\n",
    "        try:\n",
    "            artist = sp.artist(artist_id)\n",
    "            time.sleep(1.2)  \n",
    "            artist_data[\"artist_popularity\"] = artist.get(\"popularity\", None)\n",
    "            artist_data[\"artist_genres\"] = artist.get(\"genres\", [])\n",
    "            artist_cache[artist_id] = {\n",
    "                \"artist_popularity\": artist_data[\"artist_popularity\"],\n",
    "                \"artist_genres\": artist_data[\"artist_genres\"]\n",
    "            }\n",
    "            break  \n",
    "        except spotipy.exceptions.SpotifyException as e:\n",
    "            if e.http_status == 429:\n",
    "                wait_time = int(e.headers.get(\"Retry-After\", 10))\n",
    "                print(f\"ðŸ” Rate Limit {wait_time} Sek\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                print(f\"mistake {artist_id}: {e}\")\n",
    "                break\n",
    "        except Exception as e:\n",
    "            print(f\" mistake ({attempt+1}/5) bei {artist_id}: {e}\")\n",
    "            time.sleep(10)\n",
    "    else:\n",
    "        print(f\" {artist_id} mistake.\")\n",
    "\n",
    "    artist_results.append(artist_data)\n",
    "\n",
    "    if idx % 100 == 0 and idx > 0:\n",
    "        print(f\"ðŸ’¾ save after {idx} Artists...\")\n",
    "        with open(artist_cache_file, \"w\") as f:\n",
    "            json.dump(artist_cache, f, indent=2)\n",
    "        print(\"break 30s\")\n",
    "        time.sleep(30)\n",
    "\n",
    "\n",
    "with open(artist_cache_file, \"w\") as f:\n",
    "    json.dump(artist_cache, f, indent=2)\n",
    "\n",
    "\n",
    "all_artist_data = {\n",
    "    aid: {\n",
    "        \"artist_popularity\": data.get(\"artist_popularity\"),\n",
    "        \"artist_genres\": data.get(\"artist_genres\", [])\n",
    "    } for aid, data in artist_cache.items()\n",
    "}\n",
    "\n",
    "df_artist_data = pd.DataFrame([\n",
    "    {\"main_artist_id\": aid, **data} for aid, data in all_artist_data.items()\n",
    "])\n",
    "\n",
    "\n",
    "df_part = df_part.merge(df_artist_data, on='main_artist_id', how='left')\n",
    "\n",
    "\n",
    "df_cleaned = df_cleaned.merge(\n",
    "    df_part[['main_artist_id', 'artist_popularity', 'artist_genres']],\n",
    "    on='main_artist_id',\n",
    "    how='left'\n",
    ")\n",
    "\n",
    "\n",
    "print(df_part[['name', 'main_artist_id', 'artist_popularity', 'artist_genres']].head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d951a3-1314-47db-a840-9a38c310bdac",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part.to_csv(f\"df_part_{part_index+1}_with_artist_data.csv\", index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933ea15e-966c-40ab-b018-ab56979c5dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part4 = pd.read_csv(\"df_part_4_with_artist_data.csv\")\n",
    "\n",
    "df_part4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cce4b3e-e22a-4c4d-a568-bad295491f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part3 = pd.read_csv(\"df_part_3_with_artist_data.csv\")\n",
    "\n",
    "df_part3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2b33e0-728b-4f8f-9289-d0d395bb2c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part1 = pd.read_csv(\"df_part_1_with_artist_data.csv\")\n",
    "\n",
    "df_part1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95ac0d36-82d7-4882-8146-e0a8065aca6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part2 = pd.read_csv(\"df_part_2_with_artist_data.csv\")\n",
    "\n",
    "df_part2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64704094-996c-4374-9f6a-89e798e920fc",
   "metadata": {},
   "source": [
    "## Getting the Lyrics from Genius API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d31ef78a-0efd-4805-95bb-7bf4f8cbcf27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lyricsgenius\n",
    "\n",
    "genius = lyricsgenius.Genius(\"3WzY80WxnfShX6S_gf5CVS6U7d6CmrOpueI7bm7T_RBveLSSwWoqEGOZxMRQEr1W\")\n",
    "genius.skip_non_songs = True\n",
    "genius.excluded_terms = [\"(Remix)\", \"(Live)\"]\n",
    "genius.verbose = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4548e557-60b5-4322-8c28-8a73dacf4a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lyrics(title, artist):\n",
    "    try:\n",
    "        song = genius.search_song(title, artist)\n",
    "        if song and song.lyrics:\n",
    "            return song.lyrics\n",
    "    except Exception as e:\n",
    "        print(f\"Fehler bei {title} - {artist}: {e}\")\n",
    "    return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f795ab-d0e1-4a5f-bb16-bb106bba708e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time  \n",
    "\n",
    "lyrics_dict = {}\n",
    "\n",
    "for i, row in tqdm(full_dataset.iterrows(), total=full_dataset.shape[0]):\n",
    "    track = row['name']\n",
    "    artist = row['artists'][0] if isinstance(row['artists'], list) else row['artists']\n",
    "    \n",
    "    if (track, artist) not in lyrics_dict:  \n",
    "        lyrics = get_lyrics(track, artist)\n",
    "        lyrics_dict[(track, artist)] = lyrics\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2dcd99-58d8-46c5-91e6-396641c68210",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cached_lyrics(row):\n",
    "    track = row['name']\n",
    "    artist = row['artists'][0] if isinstance(row['artists'], list) else row['artists']\n",
    "    return lyrics_dict.get((track, artist), None)\n",
    "\n",
    "full_dataset['lyrics'] = full_dataset.apply(get_cached_lyrics, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac875399-1033-4565-9554-f2da0903df0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a2c76a4-026e-4562-b957-722d4e7ae91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lyricsgenius\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import json\n",
    "import os\n",
    "\n",
    "\n",
    "genius = lyricsgenius.Genius(\"3WzY80WxnfShX6S_gf5CVS6U7d6CmrOpueI7bm7T_RBveLSSwWoqEGOZxMRQEr1W\")\n",
    "genius.skip_non_songs = True\n",
    "genius.excluded_terms = [\"(Remix)\", \"(Live)\"]\n",
    "genius.verbose = False\n",
    "\n",
    "\n",
    "CACHE_FILE = \"lyrics_cache.json\"\n",
    "\n",
    "if os.path.exists(CACHE_FILE):\n",
    "    with open(CACHE_FILE, \"r\") as f:\n",
    "        lyrics_dict = json.load(f)\n",
    "  \n",
    "    lyrics_dict = {tuple(eval(k)): v for k, v in lyrics_dict.items()}\n",
    "else:\n",
    "    lyrics_dict = {}\n",
    "\n",
    "\n",
    "def get_lyrics(title, artist, retries=3, wait_time=60):\n",
    "    attempt = 0\n",
    "    while attempt < retries:\n",
    "        try:\n",
    "            song = genius.search_song(title, artist)\n",
    "            if song and song.lyrics:\n",
    "                return song.lyrics\n",
    "            else:\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            print(f\"âš¡ Fehler bei {title} - {artist}: {e}\")\n",
    "            attempt += 1\n",
    "            if attempt < retries:\n",
    "                print(f\"new try {wait_time} seconds...\")\n",
    "                time.sleep(wait_time)\n",
    "            else:\n",
    "                print(f\" {title} - {artist}.\")\n",
    "                return None\n",
    "\n",
    "\n",
    "for i, row in tqdm(df_cleaned.iterrows(), total=df_cleaned.shape[0]):\n",
    "    track = row['name']\n",
    "    artist = row['artists'][0] if isinstance(row['artists'], list) else row['artists']\n",
    "    \n",
    "    key = (track, artist)\n",
    "    \n",
    "    if key not in lyrics_dict:\n",
    "        lyrics = get_lyrics(track, artist)\n",
    "        lyrics_dict[key] = lyrics\n",
    "        \n",
    "        time.sleep(1)  \n",
    "        \n",
    "     \n",
    "        if i % 500 == 0:\n",
    "            print(f\"safe {i} Songs...\")\n",
    "            save_cache = {str(k): v for k, v in lyrics_dict.items()}\n",
    "            with open(CACHE_FILE, \"w\") as f:\n",
    "                json.dump(save_cache, f, indent=2)\n",
    "\n",
    "\n",
    "save_cache = {str(k): v for k, v in lyrics_dict.items()}\n",
    "with open(CACHE_FILE, \"w\") as f:\n",
    "    json.dump(save_cache, f, indent=2)\n",
    "\n",
    "\n",
    "def get_cached_lyrics(row):\n",
    "    track = row['name']\n",
    "    artist = row['artists'][0] if isinstance(row['artists'], list) else row['artists']\n",
    "    return lyrics_dict.get((track, artist), None)\n",
    "\n",
    "df_cleaned['lyrics'] = df_cleaned.apply(get_cached_lyrics, axis=1)\n",
    "\n",
    "print(\"lyrices succesfull\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "228f54fa-8a3a-44f7-a7be-928c9840de7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_part1 = pd.read_csv(\"df_part_1_with_artist_data.csv\")\n",
    "\n",
    "\n",
    "\n",
    "df_part2 = pd.read_csv(\"df_part_2_with_artist_data.csv\")\n",
    "\n",
    "\n",
    "\n",
    "df_part3 = pd.read_csv(\"df_part_3_with_artist_data.csv\")\n",
    "\n",
    "\n",
    "\n",
    "df_part4 = pd.read_csv(\"df_part_4_with_artist_data.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d8d847e-59cc-4335-9697-dc1de4e53375",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artist_all = pd.concat([df_part1, df_part2, df_part3, df_part4], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63c5dbc-a599-4fe6-8a49-2f79943e9281",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_artist_all['artist_genres'] = df_artist_all['artist_genres'].apply(\n",
    "    lambda x: eval(x) if isinstance(x, str) else x\n",
    ")\n",
    "\n",
    "df_with_genres = df_artist_all[df_artist_all['artist_genres'].apply(lambda x: bool(x) and len(x) > 0)]\n",
    "\n",
    "print(f\"amount artist with genre {df_with_genres.shape[0]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e065240-49be-4468-a8b1-2409b41b5323",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_genres.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (Anaconda)",
   "language": "python",
   "name": "anaconda_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
